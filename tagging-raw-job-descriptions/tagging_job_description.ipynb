{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#print(stopwords.words(\"english\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fil = pd.read_table('train1.tsv')\n",
    "test_dat = pd.read_table('test.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fil.head()\n",
    "#len(file)\n",
    "stop = stopwords.words('english')\n",
    "fil['tags'][fil['tags'].isnull()==True]=' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fil['description'] = fil['description'].apply(lambda x:''.join([word for word in x if word not in stop]))\n",
    "#fil.head()\n",
    "#test_dat['description'] = test_dat['description'].apply(lambda x:''.join([word for word in x if word not in stop]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y=[]\n",
    "x=[]\n",
    "y = fil['tags'] \n",
    "train_data = np.array(fil['description'])\n",
    "train_label = np.array(fil['tags'])\n",
    "test_data = np.array(test_dat)\n",
    "#print(train_data)\n",
    "#print(train_label)\n",
    "#print(test_data)\n",
    "#print(train_label)\n",
    "y_train=[]\n",
    "for i in range(len(fil['tags'])):\n",
    "    x=[]\n",
    "    for j in fil['tags'][i].split(' '):        \n",
    "        x.append(j)\n",
    "    y_train.append(x)\n",
    "#print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y= mlb.fit_transform(y_train)\n",
    "#print (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#fil['tags'][fil['tags'].isnull()==True]=' '\n",
    "# for i in range(len(fil['tags'])):\n",
    "#     if fil['tags'] :        \n",
    "#         fil['tags'] [i]=' '\n",
    "    \n",
    "#print (fil['tags'].isnull())    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=200000, max_features=None, min_df=9e-05,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=...ulti_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
       "     verbose=0),\n",
       "          n_jobs=1))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf = Pipeline([('tfidf', TfidfVectorizer(ngram_range=(1,3), min_df=0.00009, max_df=200000, smooth_idf=True,norm='l2',sublinear_tf=False, use_idf=True)),\n",
    "                      ('clf', OneVsRestClassifier(LinearSVC(penalty='l1',dual=False,tol=1e-3)))\n",
    "                   ])\n",
    "text_clf.fit(fil['description'],Y)\n",
    "# print(train_data.shape,len(y),len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = text_clf.predict(test_dat['description'])\n",
    "test_tmp = mlb.inverse_transform(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for i in test_tmp:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(predicted)\n",
    "#test_tmp.to_csv('foo27.tsv',sep='\\t')\n",
    "#np.savetxt('foo27.tsv',test_tmp)\n",
    "with open('foo26.tsv', 'w') as file:\n",
    "    file.writelines(' '.join(i) + '\\n' for i in test_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# y_list=[]\n",
    "# x_list=[]\n",
    "# for i in y:\n",
    "#     y_list.append(i)\n",
    "# for i in x:\n",
    "#     x_list.append(i)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vectorizer  = TfidfVectorizer(sublinear_tf=True, max_df=0.5, analyzer='word',stop_words='english')\n",
    "\n",
    "# X_train  = vectorizer.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clf = PassiveAggressiveClassifier(n_iter=50)\n",
    "# #\n",
    "# clf.fit(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mlb = MultiLabelBinarizer()\n",
    "#Y = mlb.fit_transform(str(fil['tags']))\n",
    "#print(y)\n",
    "#print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#x_list = x_list.apply(lambda x:''.join([word for word in x if word not in stop]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# count_vect = CountVectorizer()\n",
    "# X_train_counts = count_vect.fit_transform(x_list)\n",
    "# y_train_counts = count_vect.fit_transform(y_list)\n",
    "# #X_train_counts.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X_train_tf = TfidfTransformer(use_idf=False).fit_transform(X_train_counts)\n",
    "# # X_train_tf = tf_transformer.transform(tf_transformer)\n",
    "# X_train_tf.shape\n",
    "# X_train_tf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mlb = MultiLabelBinarizer()\n",
    "# Y = mlb.fit_transform(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#clf = MultinomialNB().fit(X_train_tfidf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test_data = pd.read_table('test.tsv',sep='\\t')\n",
    "#test_data['description'] = test_data['description'].apply(lambda x:''.join([word for word in x if word not in stop]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model = GradientBoostingClassifier(n_estimators = 100, learning_rate = 1.0, max_depth = 1, random_state = 0)\n",
    "#model.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "#                      ('tfidf', TfidfTransformer()),\n",
    "#                       ('clf', OneVsRestClassifier(LinearSVC()))\n",
    "#                    ])\n",
    "# text_clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
